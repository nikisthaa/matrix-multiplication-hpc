{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRgq5lbECmLX",
        "outputId": "ab0504d3-fc40-4d65-9a6c-a67aa4a4ede9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Nov  6 16:02:02 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "# Check the NVIDIA GPU\n",
        "!nvidia-smi\n",
        "\n",
        "# Check the CUDA version\n",
        "!nvcc --version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjUFEn0uDVz4",
        "outputId": "77a7b0ba-3987-4377-c279-b961002322ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-g3qzescw\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-g3qzescw\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4295 sha256=8ab074d0cc33e311f778b0c13eb9acf54b1538dae814ba8b40715b7e25d31422\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_neuj2rm/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0pE-OBsDX7u",
        "outputId": "a9cc799c-1bbc-4221-804d-154b98986889"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ],
      "source": [
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmPAHGLDD86g",
        "outputId": "712a91b8-b016-4b9a-a314-613201d5f8b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parallel Strassen Runtime (CUDA): 0.274957 seconds\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cu\n",
        "#include <iostream> // for std::cout\n",
        "#include <stdlib.h> // for malloc and free\n",
        "#include <stdio.h>  // for printf (in case you want to use it within the kernel)\n",
        "#include <cuda_runtime.h> // for CUDA runtime\n",
        "#include <time.h> // for clock\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "//Function to print a matrix to the console\n",
        "void print(int n, int** mat)\n",
        "{\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        for (int j = 0; j < n; j++) {\n",
        "            cout << mat[i][j] << \" \";\n",
        "        }\n",
        "        cout << endl;\n",
        "    }\n",
        "    cout << endl;\n",
        "}\n",
        "\n",
        "// Function to allocate memory for a 1D array representing a matri\n",
        "int* allocateMatrix(int n)\n",
        "{\n",
        "    int* data = (int*)malloc(n * n * sizeof(int));\n",
        "    return data;\n",
        "}\n",
        "\n",
        "// Function to allocate memory for a 2D array representing a matrix\n",
        "int** allocateMatrix2D(int n)\n",
        "{\n",
        "    int* data = (int*)malloc(n * n * sizeof(int));\n",
        "    int** array = (int**)malloc(n * sizeof(int*));\n",
        "    for (int i = 0; i < n; i++)\n",
        "    {\n",
        "        array[i] = &(data[n * i]);\n",
        "    }\n",
        "    return array;\n",
        "}\n",
        "\n",
        "// Function to fill a 1D array representing a matrix with random number\n",
        "void fillMatrix(int n, int*& mat)\n",
        "{\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        for (int j = 0; j < n; j++) {\n",
        "            mat[i * n + j] = rand() % 5;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// Function to fill a 2D array representing a matrix with random numbers\n",
        "void fillMatrix2D(int n, int** &mat)\n",
        "{\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        for (int j = 0; j < n; j++) {\n",
        "            mat[i][j] = rand() % 5;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// Function to create a slice of a matrix (submatrix) given offsets\n",
        "\n",
        "int** getSlice(int n, int** mat, int offseti, int offsetj)\n",
        "{\n",
        "    int m = n / 2;\n",
        "    int** slice = allocateMatrix2D(m);\n",
        "    for (int i = 0; i < m; i++)\n",
        "    {\n",
        "        for (int j = 0; j < m; j++)\n",
        "        {\n",
        "            slice[i][j] = mat[offseti + i][offsetj + j];\n",
        "        }\n",
        "    }\n",
        "    return slice;\n",
        "}\n",
        "\n",
        "// Function to add or subtract two matrices\n",
        "int** addMatrices(int n, int** mat1, int** mat2, bool add)\n",
        "{\n",
        "    int** result = allocateMatrix2D(n);\n",
        "    for (int i = 0; i < n; i++)\n",
        "    {\n",
        "        for (int j = 0; j < n; j++)\n",
        "        {\n",
        "            if (add)\n",
        "                result[i][j] = mat1[i][j] + mat2[i][j];\n",
        "            else\n",
        "                result[i][j] = mat1[i][j] - mat2[i][j];\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return result;\n",
        "}\n",
        "\n",
        "// Function to combine four submatrices into one larger matrix\n",
        "int** combineMatrices(int m, int** c11, int** c12, int** c21, int** c22)\n",
        "{\n",
        "    int n = 2 * m;\n",
        "    int** result = allocateMatrix2D(n);\n",
        "\n",
        "    for (int i = 0; i < n; i++)\n",
        "    {\n",
        "        for (int j = 0; j < n; j++)\n",
        "        {\n",
        "            if (i < m && j < m)\n",
        "                result[i][j] = c11[i][j];\n",
        "            else if (i < m)\n",
        "                result[i][j] = c12[i][j - m];\n",
        "            else if (j < m)\n",
        "                result[i][j] = c21[i - m][j];\n",
        "            else\n",
        "                result[i][j] = c22[i - m][j - m];\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return result;\n",
        "}\n",
        "\n",
        "// Function to free the memory allocated for a 1D array representing a matrix\n",
        "void freeMatrix(int n, int* mat)\n",
        "{\n",
        "    free(mat);\n",
        "}\n",
        "\n",
        "// Function to free the memory allocated for a 2D array representing a matrix\n",
        "void freeMatrix2D(int n, int** mat)\n",
        "{\n",
        "    free(mat[0]);\n",
        "    free(mat);\n",
        "}\n",
        "\n",
        "\n",
        "// Function to multiply two matrices using the naive method\n",
        "\n",
        "int** naive(int n, int** mat1, int** mat2)\n",
        "{\n",
        "    int** prod = allocateMatrix2D(n);\n",
        "\n",
        "    for (int i = 0; i < n; i++)\n",
        "    {\n",
        "        for (int j = 0; j < n; j++)\n",
        "        {\n",
        "            prod[i][j] = 0;\n",
        "            for (int k = 0; k < n; k++)\n",
        "            {\n",
        "                prod[i][j] += mat1[i][k] * mat2[k][j];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return prod;\n",
        "}\n",
        "\n",
        "// CUDA kernel to multiply two matrices\n",
        "__global__ void multiply(int* mat1, int* mat2, int* product, int n)\n",
        "{\n",
        "    int prod = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int i = prod / n;\n",
        "    int j = prod % n;\n",
        "    for (int k = 0; k < n; k++) {\n",
        "        product[i * n + j] += mat1[i * n + k] * mat2[k * n + j];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Function to perform matrix multiplication using CUDA, similar to naive but parallelized\n",
        "int** cudaNaive(int n, int** mat1, int** mat2)\n",
        "{\n",
        "    // Allocate host (CPU) memory and flatten the input matrices for GPU processing\n",
        "    int* h_mat1 = allocateMatrix(n);\n",
        "    for(int i=0;i<n;i++){\n",
        "        for(int j=0;j<n;j++){\n",
        "            h_mat1[i*n + j] = mat1[i][j];\n",
        "        }\n",
        "    }\n",
        "\n",
        "    int* h_mat2 = allocateMatrix(n);\n",
        "    for(int i=0;i<n;i++){\n",
        "        for(int j=0;j<n;j++){\n",
        "            h_mat2[i*n + j] = mat2[i][j];\n",
        "        }\n",
        "    }\n",
        " // Initialize the host (CPU) product matrix with zeros\n",
        "    int* h_product = allocateMatrix(n);\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        for (int j = 0; j < n; j++) {\n",
        "            h_product[i * n + j] = 0;\n",
        "        }\n",
        "    }\n",
        " // Calculate the number of bytes needed to store the matrix\n",
        "    size_t bytes = n * n * sizeof(int);\n",
        "\n",
        "  // Allocate device (GPU) memory for the matrices\n",
        "\n",
        "    int *d_mat1, *d_mat2, *d_product;\n",
        "\n",
        "    cudaMalloc(&d_mat1, bytes);\n",
        "    cudaMalloc(&d_mat2, bytes);\n",
        "    cudaMalloc(&d_product, bytes);\n",
        "\n",
        "   // Copy the matrices from host to device memory\n",
        "    cudaMemcpy(d_mat1, h_mat1, bytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_mat2, h_mat2, bytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_product, h_product, bytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        "    // Define the number of threads and blocks for the kernel launch\n",
        "    int threads = min(256, n);\n",
        "    int blocks = (n * n) / threads;\n",
        "    dim3 gridSize(blocks, 1, 1);\n",
        "    dim3 blockSize(threads, 1, 1);\n",
        "\n",
        "    // Launch the kernel to multiply matrices on the GPU\n",
        "    multiply<<<gridSize, blockSize>>>(d_mat1, d_mat2, d_product, n);\n",
        "    cudaDeviceSynchronize();// // Wait for GPU to finish before accessing on host\n",
        "\n",
        "    // Copy the result matrix back to host memory\n",
        "    cudaMemcpy(h_product, d_product, bytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cudaFree(d_mat1);\n",
        "    cudaFree(d_mat2);\n",
        "    cudaFree(d_product);\n",
        "\n",
        "    freeMatrix(n, h_mat1);\n",
        "    freeMatrix(n, h_mat2);\n",
        "\n",
        "    // Convert the result back into a 2D array for the host\n",
        "    int** product = allocateMatrix2D(n);\n",
        "    for(int i=0;i<n;i++){\n",
        "        for(int j=0;j<n;j++){\n",
        "            product[i][j] = h_product[i*n + j];\n",
        "        }\n",
        "    }\n",
        "    return product;\n",
        "}\n",
        "\n",
        "// Function implementing the Strassen algorithm for matrix multiplication\n",
        "int** strassen(int n, int** mat1, int** mat2)\n",
        "{\n",
        "\n",
        " // Base case: if the matrix is small enough, use the naive approach\n",
        "    if (n <= 32)\n",
        "    {\n",
        "        return naive(n, mat1, mat2);\n",
        "    }\n",
        "// Divide the matrices into four submatrices each, which will be combined later\n",
        "    int m = n / 2;\n",
        " // Extract submatrices from the first matrix\n",
        "    int** a = getSlice(n, mat1, 0, 0);\n",
        "    int** b = getSlice(n, mat1, 0, m);\n",
        "    int** c = getSlice(n, mat1, m, 0);\n",
        "    int** d = getSlice(n, mat1, m, m);\n",
        "\n",
        "// Extract submatrices from the second matrix\n",
        "    int** e = getSlice(n, mat2, 0, 0);\n",
        "    int** f = getSlice(n, mat2, 0, m);\n",
        "    int** g = getSlice(n, mat2, m, 0);\n",
        "    int** h = getSlice(n, mat2, m, m);\n",
        "\n",
        "    int** bds = addMatrices(m, b, d, false);\n",
        "    int** gha = addMatrices(m, g, h, true);\n",
        "    int** s1 = cudaNaive(m, bds, gha);\n",
        "    freeMatrix2D(m, bds);\n",
        "    freeMatrix2D(m, gha);\n",
        "\n",
        "    int** ada = addMatrices(m, a, d, true);\n",
        "    int** eha = addMatrices(m, e, h, true);\n",
        "    int** s2 = cudaNaive(m, ada, eha);\n",
        "    freeMatrix2D(m, ada);\n",
        "    freeMatrix2D(m, eha);\n",
        "\n",
        "    int** acs = addMatrices(m, a, c, false);\n",
        "    int** efa = addMatrices(m, e, f, true);\n",
        "    int** s3 = cudaNaive(m, acs, efa);\n",
        "    freeMatrix2D(m, acs);\n",
        "    freeMatrix2D(m, efa);\n",
        "\n",
        "    int** aba = addMatrices(m, a, b, true);\n",
        "    int** s4 = cudaNaive(m, aba, h);\n",
        "    freeMatrix2D(m, aba);\n",
        "    freeMatrix2D(m, b);\n",
        "\n",
        "    int** fhs = addMatrices(m, f, h, false);\n",
        "    int** s5 = cudaNaive(m, a, fhs);\n",
        "    freeMatrix2D(m, fhs);\n",
        "    freeMatrix2D(m, a);\n",
        "    freeMatrix2D(m, f);\n",
        "    freeMatrix2D(m, h);\n",
        "\n",
        "    int** ges = addMatrices(m, g, e, false);\n",
        "    int** s6 = cudaNaive(m, d, ges);\n",
        "    freeMatrix2D(m, ges);\n",
        "    freeMatrix2D(m, g);\n",
        "\n",
        "    int** cda = addMatrices(m, c, d, true);\n",
        "    int** s7 = cudaNaive(m, cda, e);\n",
        "    freeMatrix2D(m, cda);\n",
        "    freeMatrix2D(m, c);\n",
        "    freeMatrix2D(m, d);\n",
        "    freeMatrix2D(m, e);\n",
        "\n",
        "    int** s1s2a = addMatrices(m, s1, s2, true);\n",
        "    int** s6s4s = addMatrices(m, s6, s4, false);\n",
        "    int** c11 = addMatrices(m, s1s2a, s6s4s, true);\n",
        "    freeMatrix2D(m, s1s2a);\n",
        "    freeMatrix2D(m, s6s4s);\n",
        "    freeMatrix2D(m, s1);\n",
        "\n",
        "    int** c12 = addMatrices(m, s4, s5, true);\n",
        "    freeMatrix2D(m, s4);\n",
        "\n",
        "    int** c21 = addMatrices(m, s6, s7, true);\n",
        "    freeMatrix2D(m, s6);\n",
        "\n",
        "    int** s2s3s = addMatrices(m, s2, s3, false);\n",
        "    int** s5s7s = addMatrices(m, s5, s7, false);\n",
        "    int** c22 = addMatrices(m, s2s3s, s5s7s, true);\n",
        "    freeMatrix2D(m, s2s3s);\n",
        "    freeMatrix2D(m, s5s7s);\n",
        "    freeMatrix2D(m, s2);\n",
        "    freeMatrix2D(m, s3);\n",
        "    freeMatrix2D(m, s5);\n",
        "    freeMatrix2D(m, s7);\n",
        "\n",
        "    int** prod = combineMatrices(m, c11, c12, c21, c22);\n",
        "\n",
        "    freeMatrix2D(m, c11);\n",
        "    freeMatrix2D(m, c12);\n",
        "    freeMatrix2D(m, c21);\n",
        "    freeMatrix2D(m, c22);\n",
        "\n",
        "    return prod;\n",
        "}\n",
        "// Main function where the program starts execution\n",
        "int main()\n",
        "{\n",
        "    int n;\n",
        "\n",
        "    n = 1024;\n",
        "    int** mat1 = allocateMatrix2D(n);\n",
        "    fillMatrix2D(n, mat1);\n",
        "\n",
        "    int** mat2 = allocateMatrix2D(n);\n",
        "    fillMatrix2D(n, mat2);\n",
        "\n",
        "    clock_t start, end;\n",
        "    start = clock();\n",
        "\n",
        "    int** prod = strassen(n, mat1, mat2);\n",
        "\n",
        "    end = clock();\n",
        "    double time = double(end - start) / double(CLOCKS_PER_SEC);\n",
        "    cout<<\"Parallel Strassen Runtime (CUDA): \"<<time<<\" seconds\\n\";\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NX2PSFndE7Hk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
